# 后BERT时代的模型

## XLM：跨语言模型

### 优化方向

BERT本应在语义理解上具有绝对优势，但其训练预料均为英语单语，受限于此，早期的BERT只在英语文本理解上有优势。随着全球化进程的加速，跨语言预训练语言模型也具有重要的应用场景，为了探究BERT在跨语言场景中的性能，XLM（Cross-lingual Language Model，跨语言语言模型）应运而生。

XLM在不改动BERT架构的情况下，通过以下改进，让BERT拥有了跨语言能力：

- 分词操作——使用BPE（Byte Pair Encoding）编码
- 将大量单语语料扩充为双语平行预料
- 用TLM（Translated Language Modeling，翻译语言建模）训练方法替代MLM训练方法

以上三个改进是为了解决两个问题：

1. 输入文本为多语种时，未登录词过多的问题
2. 多语种文本之间词义和句义难匹配的问题

使用BPE编码是为了解决词表中未登录词过多的问题；而在训练预料中加入大量双语平行预料及采用TLM训练方法都是为了关联多语种输入文本的词义和句义。参考BERT关联两个句子语义的训练方法（NSP），可以推断出TLM训练方法的大致框架。

### 算法细节

1. BPE

   XLM用BPE作为分词工具，将多个语种的文本切割成更细细粒度的子词，利用单语种的构词规律与同一语系的语法相似性，极大地降低了词表数量，缓解了推理时未登录词过多的问题。

   不同语种的训练预料数量不同，会导致构建BPE融合词表时各语种中词的权重不平衡的问题，因此在构建BPE融合词表时，需要对训练数据进行重采样。

2. TLM

   该训练方法通过预测掩码词，让模型学会深层语义信息，与MLM不同的是，TLM的输入是两个具有相同含义，但语种不同的句子，即输入语料从单语文本转变成了双语平行预料。

   将平行预料用分隔符分割，按照设定好的概率随机替换部分词为[MASK]，让模型预测掩码词。这样设置的好处在于：当模型预测掩码词时，不仅可以利用该词的单语语境的上下文，还可以直接利用平行预料中的语义，甚至是同义词。因此TLM训练方法可以让模型在提取表征向量时学习跨语言的信息编码，让预训练语言模型有了跨语言理解的能力。

   除了训练模式不同，XLM也对位置编码和分割编码做了改动，以便更好地支持TLM训练。首先对位置编码记性位置重置操作，即在平行预料后置位的语句位置从0开始技术，而非延续前置位句子计数。其次，将分割编码改为语言编码，用来区分平行预料中的两个语种。

3. 预训练流程

   高质量的平行语料不易获得，语料数量极其受限，不足以让模型获得很强的语义理解能力，而单语语料的获取方式简单且成本低，所以XLM采用MLM和TLM交叉训练的方式，在提升模型单语语义理解能力的同时，提升模型跨语言理解的能力。

## MT-DNN：多任务融合

### 优化方向

BERT需要经过相关任务数据的微调训练，才能在下游任务上有不错的表现。但是不同任务都具有不同的训练数据，语料来源也各不相同。

MT-DNN的全称为Multi-Task Deep Neural Networks for Natural Language Understanding，即自然语言处理多任务深度神经网络。MT-DNN使用多任务学习（Multi-Tasks Learning，MTL)的监督数据，进一步提升了预训练语言模型在下游任务中的表现。具体而言,MT-DNN使用多任务学习的监督数据有以下原因：

- 不少下游任务具有相同的输入和输出格式，监督学习需要大量监督数据，如果任务的训练数据较为稀少，则可以通过多任务训练的方式，提升低资源条件下模型在任务上的表现
- 通过对不同任务的训练数据进行监督学习，避免预训练语言模型对某一类任务过拟合，使模型更具普适性
- 使用多领域的监督数据对预训练语言模型进行补充训练，弥补在预训练阶段由于训练与语料单一带来的不利影响

可以用下面的例子来解释MT-DNN的本质：

> BERT是一名英雄联盟职业选手，但是他只会玩ad。现在教练要求他打上单，给他一个月的时间，他可以做到。
>
> MT-DNN也是一名英雄联盟职业选手，他除了疯狂地rank玩ad，偶尔也会打上单和中路等其他位置。现在教练要求他打上单，给他一个月或者甚至半个月的时间，他可以玩的比BERT更好。

### 算法细节

MT-DNN的模型结构与BERT完全一致，只是在输出层为不同的任务设计了独特的输出形式和优化目标函数。

如图所示，底层表示输入文本，中间4层表示多任务训练共享的模型结构和隐层数据，灰色层表示不同阶段的特征向量；顶层由4个任务相关的特殊模块并列组成，自左向右分别对应4类任务：单句分类、文本相似度、句对分类、相关性排列。

### 小结

MT-DNN在BERT的基础上，把下游任务的微调阶段放到了预训练阶段，让模型获得了更强的通用性，提升了模型的泛化能力。而且，在MT-DNN的基础上，只需要利用下游任务的训练数据，即可完成第二阶段的多任务训练，训练数据的获取难度较小。

## UniLM：获得文本生成能力

### 优化方向

UniLM（Unified Pre-trained Language Model，统一的预训练语言模型）是微软提出的，能够同时处理自然语言理解和自然语言生成任务的模型。微软此前也提出过MASS（Masked Sequence to Sequence Pre-training for Language Generation）模型以期待在BERT上获得文本生成能力。与MASS相比，UniLM不仅在结构上更简单，而且同时支持自然语言理解任务和生成任务，在性能上也有提升，故本章只介绍UniLM。

UniLM的核心思想如名称一样直白：统一自然语言处理和自然语言生成任务，即不仅继承BERT的语言理解能力，还拥有GPT的文本生成能力。

 BERT使用MLM训练方法获得了语言理解能力，GPT使用自左向右编码的标准语言模型的训练方法获得了文本生成能力，那么UniLM想要获得这两种能力，是否需要想MT-DNN一样使用多任务训练的方法的呢？答案是肯定的，不仅如此，UniLM还增加了自右向左编码和序列到序列编码的语言模型。

与MASS相比，UniLM的模型结构与BERT几乎一模一样，即UniLM通过调整预训练的模式，让BERT具有了文本生成能力，这是一个非常大胆却异常有效的创新。

### 算法细节

GPT和BERT的特征提取器分别使用了 Transformer Decoder和Transformer Encoder，而UniLM与BERT具有相同的结构，却具备了Decoder的能力。在第三章和第四章有两个重要的细节：

1. Transformer Decoder层与Encoder层相比，除了多了一层Encoder-Decoder Attention，单向编码和双向编码都是用掩码操作实现的，即Self-Attention部分与Encoder完全一致
2. GPT使用的Transformer Decoder没有Encoder-Decoder Attention层

结合这两个关键点，UniLM的设计思路就清晰了，即利用Self-Attention的掩码操作，让模型在Transformer Encoder和Transformer Decoder之间切换，分别训练不同的任务。

1. 单向语言模型

   单向语言模型包括自左向右编码和自右向左编码的语言模型（GPT仅为自左向右编码的语言模型）。在单向语言模型的与训练过程中，输入单个句子的文本，在自左向右编码的语言模型中，每个token的抽象特征只会利用该词左边及其本身的信息。

2. 双向语言模型

   与BERT的训练方式完全一致，利用掩码词的全部上下文信息来计算特征向量

3. 序列到序列的语言模型

   与传统的Transformer Encoder-Decoder结构实现序列到序列的转化不同，UniLM将两个句子通过分隔符拼接成一个句子，转化成单向语言模型来处理。与语言模型略有不同的是，UniLM在训练时掩码词只存在于第二个句子中，即第一个句子的所有信息对掩码词而言是全部可见的。因此第二个句子的词特征向量由第一个句子的全部信息和第二个句子的上下文信息综合得到。

### 小结

UniLM在自然语言理解任务的精确度上与BERT的表现相当，在5个生成式任务上均达到了SOTA效果。UniLM利用掩码操作和多种语言模型训练方法组合的方式，将自然语言理解任务和自然语言生成任务融合在一个预训练语言模型中，这种设计非常巧妙。

## SpanBERT：扩大掩码范围

### 优化方向

MLM训练方法是BERT拥有自然语言理解能力的核心训练方法，然而，BERT在预训练过程中挑选掩码词的概率是独立计算的，即BERT掩码词的粒度是最小的，可能是单个词，也可能是一个词的部分子词。SpanBERT的核心思想是，扩大掩码范围让模型有更好的性能。SpanBERT的改进如下：

- 提出了Span Mask方案，扩大掩码词的粒度，即不再对单个词做掩码操作，而是对局部多个连续词做掩码操作
- 将Span Boundary Objective（SBO）作为训练方法，利用掩码词附近的词信息，预测某个掩码词的内容，加强了局部上下文的信息利用，以此增强BERT在语义理解上的性能
- 舍弃NSP的训练方法，以获得更好的长文本语义理解能力

SpanBERT没有修改BERT的结构，也没有使用更多的语料，仅通过设计更合理的预训练任务和目标，使模型有更好的性能表现，思路非常独特。

### 算法细节

1. 掩码词的选择

   相比于BERT随机挑选15%的词做掩码操作，SpanBERT在实施多个词的掩码操作时设计得更为精细。实施多次掩码操作的关键有两个：连续掩码词的个数、连续掩码词的起点。

   SpanBERT利用几何分布来决定连续掩码词的个数，计算公式：$$ l = Geo(p)$$

   其中，Geo为几何分布采样函数，p为几何分布超参数，取指为0.2，l为连续掩码词的个数，限定为[1,10]。

   值得注意的是，掩码词的个数计算的是完整词的个数，而非子词的个数。掩码词的起点是随机选取的，唯一的要求是掩码词的起点必须使一个独立的词，或者是被分为若干子词的第一个子词（掩码必须覆盖完整的词以确保语义连贯性）。

2. SBO训练目标

   除了以BERT原有的预测掩码词的交叉熵作为训练目标，对连续掩码词引入掩码边界词作为辅助训练目标，可以让模型具有更好的性能。

   具体而言，在训练时，取掩码词前后边界的两个词，且这两个词不再掩码范围内，通过这两个词提取得到的特征向量，与掩码词的位置编码向量联合预测最终的词，即SBO训练方法。

### 小结

SpanBERT的主要改进点在于优化了掩码策略，引入了SBO训练方法。在绝大部分下游任务中，SpanBERT的表现均优于BERT，在抽取式问答任务上表现尤其优异。

## XLNet：置换自回归

### 优化方向

BERT获得自然语言理解能力最重要的训练方法是MLM，而MLM训练方法存在一个问题，即训练时所用的[MASK]标签不会在预测时出现。虽然BERT采用随机替换和不替换的策略减少偏差，也取得了较好的效果，但是谷歌提出的XLNet并不满足于此。

XLNet融合了BERT的自编码训练方式和GPT的自回归编码训练方式，与此同时引入Transformer-XL作为特征提取器结构。总的来说，XLNet与BERT相比，最大的创新点在于：

- 提出PML（Permutation Language Model）训练方法，解决MLM训练方法中[MASK]带来的负面影响
- 提出双流注意力机制（Two-Stream Self-Attention）配合PLM训练
- 用Tranformer-XL取代原始的Transformer，并将其作为特征提取器，将强长文本的理解能力

本质上，PLM还是自回归编码训练，因此XLNet具备生成能力，而PLM又利用了双向编码做训练，故具备了极强的语义理解能力。

XLNet引入Transformer-XL作为特征提取器，舍弃了NSP训练方法，使其对长句的理解能力有了极大的增强。

### 算法细节

1. PLM

   UniLM使用掩码矩阵，让模型在双向编码和单向编码之间切换，从而实现编码统一，但本质上，单向编码和双向编码依然是时间上独立的训练过程.

   PLM训练方法同样使用掩码矩阵实现单双向编码的统一，并且真正把单双编码融合在一次训练中，而不是两次独立训练的拼接。PLM最核心的技巧是置换（Permutation），其具体实现方式是：将一句话中的词随机交换位置，得到语序被打乱的新的词排列方式，然后用 单向编码的方式预测乱序排列的句子末尾15%的词。

   虽然单向编码使得每个词只能“看”到自己的前序词，但是通过词位置的置换操作，有很大概率让每个词在前序词中看到自身的上下文信息，从而达到双向编码的效果。在具体实现中，并不需要对输入语句的位置做乱序操作，位置置换的目的是改变不同词的可见区域，使用掩码矩阵即可实现。

2. 双流注意力机制

   在PLM训练中，有一个重要的细节，即每个词的掩码矩阵是遮住自身信息的。在BERT中，为了不引入预测词自身的信息，需要预测的词汇被替换成[MASK]。在GPT中，需要根据上文预测下一个词的概率。而PLM训练采用特制的掩码矩阵，与标准的单向编码相比，最大的区别在于词义信息会随着网络加深而丢失。

   为了解决PLM训练方法带来的信息传递缺失问题，XLNet专门设计了配套的双流注意力机制。双流指的是内容信息流和位置信息流，内容信息流用h表示，用于解决信息确实的问题，其掩码矩阵在词自身的位置保留语义信息；位置信息流用g表示，其使用的掩码矩阵严格按照PLM的训练要求，即只能利用词的位置信息，看不见词的语义信息。

   在内容信息流的计算过程中，掩码矩阵保留自身的词信息以防止信息丢失，可以将其视为信息存储流。在计算位置信息流的过程中，不得使用当前词的内容信息，只能通过上下文的内容信息进行计算。双流注意力机制本质上就是引入一个额外的信息存储流来解决PLM训练方法。

   3. Transformer-XL

      Transformer-XL是谷歌提出的适用于超长文本的、具有捕获长距离依赖的Transformer结构的语言模型。

      受Transformer性能的限制，BERT不得不将连续文本你切割成最长为512歌词的小段落，作为单独的训练语料进行训练，这种处理方式丢失了长文本之间的语义依赖。

      Transformer-XL借鉴了RNN的状态传递的思想，设计了段循环机制，将一个超长文本分割成若干固定长度的段落，为了让段落之间的信息能够传递，引入状态变量mermory，用于记录前一段文本数据在网络中每一层的隐层状态；在下一个段落的训练及预测过程中，加入上一个段落的memory状态变量，即可获得长距离依赖。

      除了引入段循环机制，Transformer-XL将绝对位置编码改为相对位置编码。在引入段循环机制之后，绝对位置编码的方式不再使用，因为在段落1中绝对位置为1的词，在段落2中的绝对位置会发生变化。而相对位置编码不再关心词的绝对位置，只考虑计算Self-Attention时两个词的相对距离，完美地契合了段循环机制。

      位置编码在Embedding层就完成计算了，那要怎么根据不同的段落和位置进行调整呢？事实上，Transformer-XL在计算Self-Attention时引入了相对位置编码，即对每一层Transformer Block，都利用了词的相对位置信息，从而取代了Embedding层的位置编码。



## ERNIE：知识图谱

### 优化方向

ERNIE（Enhanced language RepresentatioN with Informative Entites，使用信息实体增强语言表示）是清华大学团队和华为诺亚方舟实验室于2019年提出的融合知识图谱的预训练语言模型。

已有的预训练模型很少考虑知识信息，只利用大规模但与数据让模型自行学会语义抽象和关联。知识图谱能提供丰富的结构化知识，是一个可解释、易维护的语义知识库，如果现有的预训练语言模型能融合知识图谱，是否能让模型对自然语言的理解更上一层楼呢？ERNIE就是基于这个想法，将知识图谱引入预训练语言模型，并取得了不错的效果，其创新点在于：

- 在BERT的基础上附加了知识融合模块，将BERT的语义信息与知识图谱的实体相关联
- 提出针对知识融合的训练方法dEA（denoising Entity Auto-encoder）

ERNIE的设计思路就是在BERT的处理流程之后，通过知识图谱为语料中的实体添加更多的信息，让实体的语义更具体和丰富。

### 算法细节

1. 模型结构

   相比于之前的模型在局部算法和训练方法上做改动，ERNIE大刀阔斧地在BERT的基础上对模型结构做了较大的改动。ERNIE主要由两部分组成，第一部分是文本编码器，由N个Transformer Encoder组成，视为BERT；第二部分是知识编码器，由M个自定义的知识融合层组成，ERNIE的核心在于知识融合层的设计。

2. dEA

   ERNIE和BERT都采用了MLM和NSP的训练方法，为了让模型更好地融合知识图谱的试题信息，ERNIE提出了一种新的训练目标，即实体关联性预测。dEA训练方法让模型在有噪声的情况下学习$p(e_k|w_j)$ 的真实概率分布，从而更好地将知识图谱的信息融入语言模型中

### 小结

从性能上分析，在于信息实体相关的任务中，ERNIE大幅超越了BERT，说明了模型确实吸收了信息实体的知识，但在其余任务中，其与BERT的性能相仿，也侧面反映了知识图谱的融合并没有想象中的有效，

## VideoBERT：多模态融合

### 优化方向

VideoBERT是谷歌提出的将视频信息融入BERT的经典模型，利用BERT的强大性能，关联视频与文本信息，让模型学会了关联视频内容和文本内容，在跨模态预训练语言模型上开拓出新的方向。总体而言，VideoBERT的主要创新点如下：

- 将视频信息向量化，与文本信息一起用BERT处理
- 将NSP的训练方法更改为视频信息和文本信息关联的训练方法
- 采用预训练语言模型作为文本生成视频和视频生成文本的系统特征提取器

在模型结构方面，VideoBERT沿用了$BERT_{LARGE}$的结构，没有特殊改动；在训练数据处理方面，VideoBERT在视频信息的处理、过滤和对齐上做了大量工作。虽然NSP训练方法因为被认为不利于模型学习长文本信息而被多个模型弃用，但是在视频信息和文本信息关联的任务中仍然相当有效，VideoBERT作为跨模态预训练语言模型，可以很好地适配各类下游任务，甚至可以充当跨模态生成框架的特征提取器，同样证明其优秀的性能和普适性。

### 算法细节

1. 视频数据处理

   考虑到视频的内容维度过于广泛，难以搜集足够的数据拟合真实世界中视频的分布，故Video选取了烹饪主题的视频进行训练，视频中只有较少的元素，大大缩小了内容维度，便于模型在有限训练集上收敛。

   为了获得与视频对应的文本内容，对每个视频的音频进行ASR（Automatic Speech Recognition，自动语音识别）处理，得到与视频内容相对应的文本。然后对文本进行过滤，筛选出语句通顺、语义明确的文本与视频一一对应。

   将通过ASR得到的文本数据用于BERT一致的分词方法进行处理，而视频被降采样后则会按帧处理，使用预训练的视频理解模型S3D将30帧图像提取成一个1024维的向量。为了获得更好的区分度与表征，再对视频特征向量进行分层K-means聚类，得到20736个聚类中心，每一个聚类中心代表一类视频内容。将这些聚类中心加入模型词表中，与原有词汇共同组成新的词表，Embedding层也做相应的扩展。最终，VideoBERT得到三类训练数据：

   - 纯文本数据，与BERT一模一样的数据集
   - 纯视频数据，YouTuBe烹饪题材视频
   - 视频-文本对齐数据

2. 预训练数据

   针对三类训练数据，VideoBERT分别采取MLM和NSP训练方法，纯文本数据和纯视频数据均采用没LM训练方法，视频-文本对齐数据则采用NSP训练方法。

   VideoBERT的文本序列和视频序列用分隔符‘[>]’拼接，文本序列经Embedding层转化为1024维特征向量，而视频序列经过S3D也转化为1024为特征向量，同纬度的特征向量可以进行Self-Attention计算。

   MLM训练方法可以很自然地从纯文本拓展到视频信息，NSP训练方法被用于预测文本信息与视频信息是否一致（在BERT中用于判断两个文本的语义是否连续），用二分类的训练方法让模型学会视频信息与文本信息的融合理解。

### 小结

在BERT的基础上，VideoBERT几乎没有做任何修改，仅通过视频图像特征提取和聚类，将其转化为与文本向量形式一致的向量，从而很好地融合了视频信息和文本信息。

## ALBERT：参数共享

### 优化方向

随着模型规模的持续增大，单块GPU已经无法容纳整个预训练语言模型，为了解决这个问题，谷歌提出了ALBERT，其与BERT几乎没有区别，但其占用的显存空间可以减少至BERT的十分之一甚至更少，方便了预训练语言模型的训练和部署。

为了不大幅降低模型的性能，ALBERT有如下几点改进：

- Embedding层低秩分解
- 跨层参数共享
- 使用SOP（Sentence Order Prediction）训练方法代替NSP训练方法

Embedding层低秩分解是为了固定Embedding层的参数规模，使其不随模型的增大而增大。

跨层参数共享则让模型只记住一个Transformer Block的参数，就可以还原真个模型，大大减少了参数存储的空间，是ALBERT效果突出的最重要原因。

NSP训练方法已经被诸多模型证明没有效果，故ALBERT采用了SOP训练方法，并用实验证明其有效。

### 算法细节

1. Embedding层低秩分解

   设Embedding层的输出向量维度为E，隐层向量（Transformer Block的输入输出向量）的维度为H，模型词表大小为V。在BERT中一般默认E和H一致，即Embedding层的输出直接作为Transformer Block层的输入。

   其实Embedding层只是一个静态映射，词的向量化过程不涉及上下文信息，因此Embedding层的输出维度E没有必要随着H的增大而增大，可以保持在一定规模以免造成参数冗余。

   具体而言，ALBERT在固定E之后，引入了一个变换矩阵，该矩阵的作用是将维度为E的Embedding层输出向量变换为维度为H的向量，以便输入至Transformer Block模块。

2. 跨层参数共享

   ALBERT采用了Transformer Block层参数共享的方法来减少模型的存储参数量。为了寻找最佳的参数共享，ALBERT分别探究了以下几种情况下的模型性能：

   - 所有层的所有参数均共享
   - 只共享Multi-Head Attention层参数
   - 只共享Feed Forward层参数
   - 每M层为一组，组内共享所有参数

   从实验结果来看，ALBERT-base在只共享Multi-Head Attention层参数时可以取得最好的效果。可惜Multi-Head Attention层参数不是主要参数部分，所以参数存储空间压缩力度不够。所有层的参数都共享和只共享Feed Forward层参数均有性能上可控范围内的损失，但是压缩力度很强。对于每M层一组的共享方法，实验表明M越小，性能越好，但是参数压缩力度也越小。

   最终，ALBERT选择了性价比最高的共享所有层的方案，牺牲了一定的性能，换来极大的参数存储空间压缩比。

3. SOP训练方法

   SOP与NSP一样也是一种以句对分类标签为训练目标的训练方法，其与NSP的差别在于负样本的选取。SOP挑选正样本与NOP一样均为连续的两个句子，但与NSP随机挑选毫无语义关系的句子作为负样本不同，SOP将正样本的两个句子交换位置，作为负样本。实验表明在二分类任务中，使用SOP训练的模型相对于NSP会略胜一筹。



## RoBERTa：更大的模型

### 优化方向

现阶段，预训练语言模型总是可以通过更大的模型和更多的数据获得更好的性能，GPT系列模型就是此类优化方向的典范。RoBERTa（名字源于A Robustly Optimized BERT Pretraining Approach）是Facebook提出的在BERT基础上增加训练数据，充分训练得到的预训练语言模型，其与BERT的不同在于：

- 使用更多的训练数据
- 使用动态掩码训练

### 算法细节

1. 训练数据

   总体而言，在不改变模型大小的情况下，使用10倍于BERT的训练数据，模型可以取得明显进步。

2. 动态掩码

   BERT的MLM训练方法使用静态掩码，其特性是处理训练数据时就讲掩码过程完成，即模型所训练的所有数据都是带有固定掩码的数据。而RoBERTa所使用的动态掩码是在输入模型时随机对输入数据进行掩码操作，即同一个训练数据在不同训练步数时所使用的掩码都不一样，其好处是在不增大训练数据集的前提下，增加模型训练的数据多样性。

   

